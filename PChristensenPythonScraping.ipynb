{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping data from the web with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to know whether we can predict mean ratings of individual rums based on price and sugar content.\n",
    "In order to do so, we need to collect (and clean) the data for analysis.\n",
    "Here, our goal will be to scrape our data from two websites before combining it in a single data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "## Part 1: Compiling a list of rum label names with sugar content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using hydrometer tests, The Finnish \"Systembolag\" and a handful of non-prefessionals decided to find out how much sugar (g/L) is added to different, mainly high-end rums. Their results for 738 rums were then shared by \"Capn Jimbo\" on his website: http://rumproject.com/rumforum/viewtopic.php?t=1683\n",
    "\n",
    "Before cleaning the data by separating label names and sugar content into separate columns, we would like to simply extract all the row and place them in new .csv file.\n",
    "\n",
    "Let us first load the necessary packages and set a directory for the .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "import csv\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "os.chdir(\"/Users/peerchristensen/Desktop/rum project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will \"scrape\" the data using xpath. We then assign each element to a variable called \"rums\". Before doing this, we must first look \"under the hood\" of the website, i.e. inspecting the underlying code, to see which CSS class we're looking for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAppleton Estate Extra 12yr: 0\\tthefatrumpirate\\t0\\r\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('http://rumproject.com/rumforum/viewtopic.php?t=1683&sid=b522a1521334abe1096817edfa299933')\n",
    "contents = html.fromstring(page.content)\n",
    "rums = contents.xpath('//span[@class=\"postbody\"]/text()')\n",
    "rums[66]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason, I wasn't able to complete the next steps in a single for loop, so we start by creating an empty list called \"rums2\" and then append each element that we previously stored in \"rums\". I couldn't quite figure out how to encode the text the optimal way, but this solution works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAppleton Estate Extra 12yr: 0\\tthefatrumpirate\\t0\\r\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rums2 =[]\n",
    "for rum in rums:\n",
    "    rums2.append(rum.encode('ascii', 'ignore'))\n",
    "rums[66]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create our file called \"rumlist.csv\" and paste each element of \"rums2\" as a separate row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"rumlist.csv\", 'w') as rumSugar:\n",
    "    wr = csv.writer(rumSugar, quoting=csv.QUOTE_ALL)\n",
    "    for rum in rums2:\n",
    "        wr.writerow([rum])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will however need some cleaning using so-called regular expressions. I've done this in R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Scrape mean rum ratings and attach meta data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we would like to scrape some mean ratings and create more variables containing information about price in USD, country of origin and classification (e.g. aged, spiced, gold). We also want to know how many raters there are for each rum and determine a minimum number of raters. We scrape all of this data from the following site: \n",
    "https://www.rumratings.com/brands?action=index&controller=brands&order_by=number_of_ratings\n",
    "\n",
    "From inspecting the website, we know that we want data from the first 21 pages ordered by number of raters. We now create a list called \"urls\" and fill it with each page. Seeing how the pages are organized, we can do this using a simple for loop to recursively add pages to our list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.rumratings.com/brands?letter=&order_by=number_of_ratings&page=0',\n",
       " 'https://www.rumratings.com/brands?letter=&order_by=number_of_ratings&page=1',\n",
       " 'https://www.rumratings.com/brands?letter=&order_by=number_of_ratings&page=2',\n",
       " 'https://www.rumratings.com/brands?letter=&order_by=number_of_ratings&page=3']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls=[]\n",
    "for i in range(0,21):\n",
    "        urls.append('https://www.rumratings.com/brands?letter=&order_by=number_of_ratings&page=%d' % (i))\n",
    "urls[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good.. We would then like to separate the data according to the aforementioned variables. Unfortunately, our data are grouped so that we need an intermediate step in order to isolate and extract the information we want.\n",
    "\n",
    "We first create three empty lists and fill them with the CSS classes shown in the below code. In order to scrape data recursively from multiple pages, we can use a package like \"BeautifulSoup\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each page (each url in \"urls\"), we place each instance of the CSS class \"rum-title\" in our list called \"rum_data\".\n",
    "These are the names of the individual rums. In the same way, and in the same for loop, we assign instances of the CSS classes \"rum-info\" and \"rum-rating-icon\" to separate lists. The \"rum_info\" list will need some further unpacking as it now contains three individual variables (price, country and classification). Importantly, each element of our three variables is actually a list (one per webpage/iteration) containing a list with information on each rum on a particular page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rum_data=[]\n",
    "rum_info=[]\n",
    "rum_ratings=[]\n",
    "\n",
    "for url in urls:\n",
    "    r=requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    rum_data.append(soup.find_all(\"div\",{\"class\":\"rum-title\"}))\n",
    "    rum_info.append(soup.find_all(\"div\",{\"class\":\"rum-info\"}))\n",
    "    rum_ratings.append(soup.find_all(\"div\",{\"class\":\"rum-rating-icon\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"rum-info\">\n",
       "Dominican Republic | Aged | 31 ratings\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rum_info[9][9]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, let's get the label names. This seems overly complicated and could be done more elegantly. The reason for this mess is that the following lines of code do several things. Here we slice list elements from embedded lists, clean each element a bit (though it would probably have been better to have left this for later) and deal with encoding in yet another loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Diplomatico 2000 Single Vintage'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labs=[]\n",
    "for i in rum_data:\n",
    "    for j in i:    \n",
    "        labs+= j\n",
    "labs=labs[::5]\n",
    "labels=[]\n",
    "for i in labs:\n",
    "    labels.append(str(i).strip(\"\\n\").rstrip())\n",
    "labels2=[]\n",
    "for i in labels:\n",
    "    labels2.append(i.encode('ascii','ignore'))\n",
    "labels[88]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then do the same for the variables that we may later use as predictors of mean ratings. As mentioned earlier, all this info is embedded in the \"rum_info\" variable, so we need to extract and clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "info=[]\n",
    "for i in rum_info:\n",
    "    for j in i:    \n",
    "        info+= j\n",
    "info2=[]\n",
    "for i in info:\n",
    "    info2.append(str(i).split(\"|\"))\n",
    "\n",
    "country=[]\n",
    "category=[]\n",
    "n_ratings=[]\n",
    "price=[]\n",
    "for i in info2:\n",
    "    country.append(i[0].strip(\"\\n\").rstrip())\n",
    "    category.append(i[1].strip(\" \"))\n",
    "    n_ratings.append(i[2].strip(\"\\n ratings\").rstrip().lstrip())\n",
    "    try:\n",
    "        price.append(i[3].strip(\"\\n $\").rstrip().lstrip())\n",
    "    except:\n",
    "        price.append(\"NA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then get the mean ratings.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rats=[]\n",
    "for i in rum_ratings:\n",
    "    for j in i:    \n",
    "        rats+= j\n",
    "ratings=[]\n",
    "for i in rats:\n",
    "    ratings.append(str(i).strip(\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we just need to write our file called \"rumratings.csv\" with our variables neatly organized in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"rumratings.csv\", 'w') as rumRating:\n",
    "    wr = csv.writer(rumRating,delimiter=';', quoting=csv.QUOTE_ALL)\n",
    "    wr.writerows(zip(labels2,country,category,ratings,n_ratings,price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
